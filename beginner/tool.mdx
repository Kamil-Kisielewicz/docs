---
title: "Build a custom tool"
description: "Subtitle (optional)"
icon: circle-1
---

## Tutorial Overview

In this tutorial, we're going to build a simple DAG workflow that will take a random cat fact generated by an API, a random cat fact generated by an LLM, and ask an LLM to determine which one was generated by an LLM.
In order to do this, we'll need to build a custom tool to get the two respective random facts, prepare the LLM, and connect them together in our DAG.

The final DAG will look like this:
```
cat_fact_tool ----\
                    llm_tool ---> llm_explanation_tool 
random_fact_tool -/
```
## Prerequisites

Please make sure you have completed the [Getting Started](../getting-started) tutorial before starting this one.

## Building the cat fact tool

### Overview
For this part of the tutorial, we'll be using a [free API](https://catfact.ninja) to get random cat facts.
We'll need to extend the `Node` class and call the API using `aiohttp` to make the most of the asynchronous nature of Trellis.

### Imports
To start, let's import all the modules we'll need for this tool.

```python cat_fact_tool.py

from trellis import Node
import aiohttp
```

### Extending Node
Next, we'll extend `Node` to create our new CatFactsAPITool class. The only required functions to implement are the constructor and `execute`.

```python cat_fact_tool.py
class CatFactsAPITool(Node):
```

### Writing `CatFactsAPITool` constructor
To effectively write our constructor, we need to understand the arguments that `Node` takes.

```python cat_fact_tool.py
    def __init__(
        self,
        name: str,
        *args,
        **kwargs,
    ) -> None:
        input_s = {}
        output_s = {"cat_information": list[dict[str, str]]}
        super().__init__(name, input_s, output_s, *args, **kwargs)
```

There's a lot going on here, so let's break it down.

- `name` is the name of the tool. Each Node generates a uuid to identify it, so `name` is simply used to make the `Node` and `DAG` human-readable.
- `input_s` is a dictionary of the inputs that the tool expects from other `Node`s as Python types. The keys are the names of the inputs, and the values are the types of the inputs. 
In this case, we will expect the `DAG` to set these arguments via `set_execute_args`, so we can leave it as an empty dictionary. 
If we instead expected this input to come exclusively from another `Node`, we would need to change the input_s to reflect that.
- `output_s` is a dictionary of the outputs that the tool produces as Python types. The keys are the names of the outputs, and the values are the types of the outputs.
In this case, we produce a single output called `cat_information` that is a list of dictionaries, where each dictionary has string keys and string values. This is the format that the API returns, so we'll keep it as is.
- `*args` and `**kwargs` are used to pass any additional arguments to the `Node` constructor. They're included within the Node constructor by default for flexibility if you want to initialize `execute_args` via the constructor.

For more information on `Node`, visit the [Reference section](../../reference/node).

### Writing CatFactsAPITool `execute`
The `execute` function is where `Node` assumes your business logic will be called. For this example, the only thing
we need to do is get the arguments for calling the CatFacts API, call the API, and return the result. `execute` is 
defined as an asynchronous function so Trellis can be more performant.

#### Getting the arguments
The first thing we need to do is get the arguments that the `DAG` will have set in our `Node` for us. We can do this using the `safe_get_execute_arg` function.
`safe_get_execute_arg` takes the name of the argument and a default value to return if the argument is not set. It also handles collisions between `input` and `execute_args`
and prioritizes `input` if the same argument is set in both places; this behavior is discouraged but the safety check is built into the framework so you don't have to
manually check every argument should you want to be flexible about how the data flows into your `Node`.

In this case, we only need to provide two arguments: `limit` and `max_length`. `limit` is the number of cat facts we want to get, and `max_length` is the maximum length of the cat facts we want to get.
```python cat_fact_tool.py
    async def execute(self) -> None:
        limit: int = self.safe_get_execute_arg("limit", 1)
        max_length: int = self.safe_get_execute_arg("max_length", 140)
```

#### Calling the API
Next, we need to call the API. We'll use `aiohttp` to do this. `aiohttp` is a popular asynchronous HTTP client for Python that is well-supported and easy to use.
```python cat_fact_tool.py
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"https://catfact.ninja/facts?limit={limit}&max_length={max_length}"
            ) as response:
```
Once we get the result, we need to set `Node`'s `output` value to the output of the API call, so that our `LLM` can use its result. We can do this using `set_output`.

```python cat_fact_tool.py
                if response.status == 200:
                    data = await response.json()
                    self.set_output({"cat_information": data["data"]})
```

Since the rest of the pipeline depends on the output, we'll throw an error if the API call fails. While we'll default to raising errors in this tutorial, 
how you handle internal errors in-practice is a design decision that is completely up to you.

```python cat_fact_tool.py             
                else:
                    raise ValueError(f"Failed to get cat facts: {response}")
```

### Putting it all together
That's it for the `CatFactsAPITool`! The final code should look like this:

```python cat_fact_tool.py

from .. import Node
import aiohttp

import asyncio


class CatFactsAPITool(Node):
    def __init__(
        self,
        name: str,
        *args,
        **kwargs,
    ) -> None:
        input_s = {}
        output_s = {"cat_information": list[dict[str, str]]}
        super().__init__(name, input_s, output_s, *args, **kwargs)

    async def execute(self) -> None:
        max_length: int = self.safe_get_execute_arg("max_length", 140)

        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"https://catfact.ninja/facts?limit={limit}&max_length={max_length}"
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    self.output = {"cat_fact_1": data["data"]}
                    return self.output
                else:
                    raise ValueError(f"Failed to get cat facts: {response}")
```

Move onto the next section to write the OpenAI calls for your `LLM` nodes.